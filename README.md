# Snopes Fake-News Classifier
## Code:
1) Scraped Snopes Website for Articles from January-July 2025. 
2) Predict whether a Snopes fact-check article is True or False using classic NLP (TF-IDF) and a linear classifier.
Inputs are kept separate (title, category, body) and vectorized column-wise to preserve signal per field.

## Quick Run-down
ğŸ§¹ Clean, modular text pipeline (stopwords, basic cleaning)

ğŸ”¤ Column-wise TF-IDF (title / category / body) via ColumnTransformer

âš–ï¸ Class-imbalance aware training (class_weight='balanced')

ğŸ“ˆ Clear evaluation: classification report, confusion matrix, ROC-AUC

ğŸšï¸ Threshold tuning to trade precision/recall for the â€œFalse (fake)â€ class

## Data

Each row corresponds to a Snopes fact-check.

### Features

title (str)

category (str) â€” e.g., Politics, History, etc.

body (str) â€” article text (or summary/snippet)

### Target

binary_Tf (bool) â€” True if the claim was rated true, False otherwise

## Results
**Accuracy:** 0.9392

| Class         | Precision | Recall | F1-Score | Support |
|--------------|-----------|--------|----------|---------|
| False        | 0.93      | 0.74   | 0.83     | 35      |
| True         | 0.94      | 0.99   | 0.96     | 146     |
| **Accuracy** | â€”         | â€”      | **0.94** | 181     |
| **Macro avg**    | 0.93      | 0.86   | 0.89     | 181     |
| **Weighted avg** | 0.94      | 0.94   | 0.94     | 181     |
***
## Next steps / Ideas

ğŸ” GridSearchCV on TF-IDF n-grams, max_features, and C

ğŸ§ª Calibrated probabilities (Platt / isotonic) for better thresholding

ğŸ§  Try linear SVM (LinearSVC) or distilBERT baseline (HuggingFace)

ğŸ“Š Per-column interpretability: show top weighted n-grams for each class
***

@software{snopes_classifier,
  title = {Snopes Fake-News Classifier},
  author = {Dinesh, Dyuthi},
  year = {2025},
  url = {https://github.com/dyuthiii/Snopes}
}
